{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIGHUM100PROJ_JasperZhou",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPFJdshb/MIvIeR5rFVDTMH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasperJZhou/DH100Proj/blob/main/DIGHUM100PROJ_JasperZhou.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwAhOvvUZ4bw"
      },
      "source": [
        "##**0) IMPORT STATEMENTS**\n",
        "\n",
        "Importing Data Analysis Tools and mounting the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJP0cjyxUd9y",
        "outputId": "38e48b17-09df-4272-a32d-9f2e2c6563f8"
      },
      "source": [
        "#Mounting Google Drive:\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Jasper Zhou/' #Change this to your root path\n",
        "drive.mount(\"/content/gdrive\", force_remount=True) \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-18sLzqMVt4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb08499-0a90-4ecb-dc4e-4d31aaeb0de5"
      },
      "source": [
        "#IMPORT STATEMENTS:\n",
        "\n",
        "#General data analysis tools \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib as plt\n",
        "\n",
        "#NLTK Tools\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import nltk.tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re #regular expression\n",
        "\n",
        "#Model Building Tools:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Classification Algorithms\n",
        "from sklearn.naive_bayes import MultinomialNB #Naive Bayes\n",
        "from sklearn import svm #Support Vector Machine\n",
        "from sklearn import linear_model #Logistic Regression"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4gjny-XaNdA"
      },
      "source": [
        "##**I) LOADING THE DATASET:**\n",
        "Create a DataFrame using pandas with our downloaded data (in folder marked data)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neQFtNXaaE4u"
      },
      "source": [
        "true_df = pd.read_csv(root_path + '/data/True.csv') #DataFrame with True headlines (Is Not Fake News)\n",
        "fake_df = pd.read_csv(root_path + '/data/Fake.csv') #DataFrame with Fake headlines (Is Fake News)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHRqtKeQef36"
      },
      "source": [
        "#Label our data (1 for fake news, 0 for true news)\n",
        "true_df[\"Is_Fake\"] = np.zeros(true_df.shape[0])\n",
        "fake_df[\"Is_Fake\"] = np.ones(fake_df.shape[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "MrcpvQgee-Hz",
        "outputId": "e8d68b71-fd0b-4d4e-c685-639507946a65"
      },
      "source": [
        "#Combine DataFrames into a CombinedFrame:\n",
        "combined_df = true_df.append(fake_df).sample(frac = 1) #randomize our data\n",
        "combined_df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>Is_Fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13949</th>\n",
              "      <td>WHOA! West Virginia Coal Miners Just Made Powe...</td>\n",
              "      <td>The economic devastation is very real in West ...</td>\n",
              "      <td>politics</td>\n",
              "      <td>May 9, 2016</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8694</th>\n",
              "      <td>Trump staff writer takes responsibility for Me...</td>\n",
              "      <td>CLEVELAND (Reuters) - A staff writer of the Tr...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>July 20, 2016</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19786</th>\n",
              "      <td>Nothing should change, says Britain in bid for...</td>\n",
              "      <td>LONDON (Reuters) - Britain proposed a new post...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>September 18, 2017</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14561</th>\n",
              "      <td>BREAKING NEWS: Obama To Meet With Special Gues...</td>\n",
              "      <td>Has our lawless President finally conceded tha...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Jan 31, 2016</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9177</th>\n",
              "      <td>JUST IN: DISGRACED DEMOCRAT HARRY REID Funnele...</td>\n",
              "      <td>The Defense Department secretly set up a progr...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Dec 17, 2017</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  ... Is_Fake\n",
              "13949  WHOA! West Virginia Coal Miners Just Made Powe...  ...     1.0\n",
              "8694   Trump staff writer takes responsibility for Me...  ...     0.0\n",
              "19786  Nothing should change, says Britain in bid for...  ...     0.0\n",
              "14561  BREAKING NEWS: Obama To Meet With Special Gues...  ...     1.0\n",
              "9177   JUST IN: DISGRACED DEMOCRAT HARRY REID Funnele...  ...     1.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynq4w6chefTu"
      },
      "source": [
        "##**II)INTRODUCTION**\n",
        "\n",
        "#Project Statement\n",
        "The goal of this project is two-fold:\n",
        "\n",
        "A)Can we analyze how the rhetoric around fake news has changed throughout time?\n",
        "\n",
        "B)Can we create an effective model to classify fake and real news?\n",
        "\n",
        "#Background\n",
        "\n",
        "To start, a definition of fake news is needed. While many definitions exist, a good, succinct one comes from the University of Michigan's library, which defines fake news \"as those news stories that are false: the entire story itself is fabricated, with no verifiable facts, sources or quotes\" (Source: [University of Michigan](https://guides.lib.umich.edu/fakenews)).\n",
        "\n",
        "Fake news has recently taken center stage in the public conciousness, popularized by tweets by Donald Trump in the run up to the 2016 presidential election. However, this project will not focus on the media relations of Donald Trump. Instead, this project will focus on the nature of fake news itself in terms of content.\n",
        "\n",
        "Fake news is not a recent or unique issue, although it has been exacerbated by the ease and speed in which information could be spread. Since the 1890s, fake news has plagued the profession of journalism. Dubbed \"yellow journalism\", newspaper publishers would run sensationlistic news articles. However, fake news was eventually replaced by objective journalism, until recently due to the rise of the internet. (Source: [UCSB](https://www.cits.ucsb.edu/fake-news/brief-history)).\n",
        "\n",
        "Unfortunately, the future seems bleak for traditional, objective news outlets. In 2016, Politico reported the findings of the Pew Research Center's \"State of the Media 2016\", noted that \"[a]dvertising revenue is down; staffs continue to get cut; the number of newspapers has declined by 100 since 2004\". (Source: Politico). As a result, we are moving towards a new world \"where the majority of the population does not reply on professionally reported news sources\" (Source: [Politico](https://www.politico.com/magazine/story/2016/12/fake-news-history-long-violent-214535)).\n",
        "\n",
        "In terms of impacts fake news has on society, University of Michigan lists the following as possibility:\n",
        "\n",
        "**A) Anti-intellectualism:** We have seen during this past year due to COVID-19, fake social media stories have run amok spanning from fake treatments to vaccine scares. Often, these issues stem from a distrust of domain knowledge experts. For example, according to a letter written to NCBI, several incidents exemplified this. In a particularly greivious instance in Mexico:\n",
        "\n",
        "\n",
        "> [T]here have been reports of health personnel having hot coffee or bleach thrown at them on the streets, as well as attempts to burn their homes, and even beatings of nurses and doctors; in some towns, the habitants have even arranged to burn COVID-19-designated hospitals. (Source: [NCBI](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7722992/))\n",
        "\n",
        "**B)Antiscience:** Similar to anti-intellectualism, there has been a startling rise in anti-scientific theories. For example, the Flat Earth movement has demonstrated the power of social media in overturning what used to be a universally accepted truth. In an interview with Scientific American, Michael Marshall noted that the Flat Earth movement's rise is closely correlated with the technology we have available. In his interview, a contributing factor was Youtube's video recommendation algorithm. It became very easy for individuals, who were only curious, to quickly get recommended similar videos, reinforcing their beliefs. (Source: [Scientific American](https://www.scientificamerican.com/podcast/episode/flat-earthers-what-they-believe-and-why/))\n",
        "\n",
        "**C)Widespread Mistrust:** In 2016, the BBC interviewed Robert Proctor who had been studying the rhetoric surrounding tobacco advertisements. The goal of these tobacco advertisements were not necessarily to discredit scientific literature and studies, but to create enough doubt surrounding the scientific community at large. Prior to 2016, similar strategies were used surrounding Barack Obama's birth certificate. While Obama was undoubtedly American, the rumor successfully created enough doubt around Obama's birth place to create an unncessarily harmful and dangerous scandal. (Source: [BBC](https://www.bbc.com/future/article/20160105-the-man-who-studies-the-spread-of-ignorance))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms8mOJKgiDF7"
      },
      "source": [
        "##**III) EDA (Exploratory Data Analysis)**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBIP3ZS1KRch"
      },
      "source": [
        "#i)Intial Pre-processing:\n",
        "First, we must pre-process the text to create text that is easily machine-readable. To do so, we undergo the following steps:\n",
        "\n",
        "\n",
        "1. Lowercase all text\n",
        "2. Tokenize the sentence into individual words\n",
        "3. Remove the stop words\n",
        "\n",
        "From this, we can do some initial, basic data analysis and examine the differences between real and fake news.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "First, create a small subset to develop our pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhmpM5FufBxb"
      },
      "source": [
        "import string\n",
        "#TESTER: Create small subset of data to test/create our pipeline on.\n",
        "pre_process_df_test = combined_df.sample(50, replace = False)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVTrMjYRjCCi"
      },
      "source": [
        "def remove_punctuation (text_array):\n",
        "  #This function removes the punctuation of text after tokenizing everything\n",
        "  arr = [text for text in text_array if text not in string.punctuation]\n",
        "  return arr"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufx7gHrYoC1d"
      },
      "source": [
        "#Convert the date to datetime objects\n",
        "from datetime import datetime\n",
        "\n",
        "def convert_date(date_string):\n",
        "  if date_string[-1] == \" \":\n",
        "    try:\n",
        "      str1 = datetime.strptime(date_string, '%B %d, %Y ')\n",
        "    except ValueError:\n",
        "      str1 = datetime.strptime(date_string, '%b %d, %Y ')\n",
        "    \n",
        "  else:\n",
        "    try:\n",
        "      str1 = datetime.strptime(date_string, '%b %d, %Y')\n",
        "    except ValueError:\n",
        "      str1 = datetime.strptime(date_string, '%B %d, %Y')   \n",
        " \n",
        "  return str1"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9jot7csl5hL"
      },
      "source": [
        "def remove_stopwords(text_array):\n",
        "  arr = [text for text in text_array if text not in ENGLISH_STOP_WORDS]\n",
        "  return arr"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-dQyguEMLvl"
      },
      "source": [
        "#Lowercase all titles and text\n",
        "pre_process_df_test[\"title\"] = pre_process_df_test[\"title\"].str.lower()\n",
        "pre_process_df_test[\"text\"] = pre_process_df_test[\"text\"].str.lower()\n",
        "\n",
        "#tokenize words into individual words and then remove the punctuation\n",
        "pre_process_df_test[\"tokenized_title\"] = pre_process_df_test[\"title\"].apply(word_tokenize).apply(remove_punctuation)\n",
        "pre_process_df_test[\"tokenized_text\"] = pre_process_df_test[\"text\"].apply(word_tokenize).apply(remove_punctuation)\n",
        "\n",
        "#Remove stop words\n",
        "pre_process_df_test[\"no_stopwords_title\"] = pre_process_df_test[\"tokenized_title\"].apply(remove_stopwords)\n",
        "pre_process_df_test[\"no_stopwords_text\"] = pre_process_df_test[\"tokenized_text\"].apply(remove_stopwords)\n",
        "\n",
        "#Convert date string to datetime objects for ease of analysis\n",
        "pre_process_df_test[\"date\"] = pre_process_df_test[\"date\"].apply(convert_date)\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJz9fmltm1Xx"
      },
      "source": [
        "---\n",
        "Now, we can apply our pipeline to our dataframe in general"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9PQQKh4m1Bp"
      },
      "source": [
        "def pre_process_pipeline(input_df):\n",
        "  #INPUT: DataFrame containing title, text, subject, date, and Is_Fake (a boolean value with 1 for fake, 0 for true)\n",
        "  #OUTPUT: DataFrame containing above columns and tokenized title and text\n",
        "  input_df[\"processed_title\"] = input_df[\"title\"].str.lower().apply(word_tokenize).apply(remove_punctuation).apply(remove_stopwords)\n",
        "  input_df[\"processed_text\"] = input_df[\"text\"].str.lower().apply(word_tokenize).apply(remove_punctuation).apply(remove_stopwords)\n",
        "  input_df[\"date\"] = input_df[\"date\"].apply(convert_date)\n",
        "  return input_df"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KUPnWtIlm6Y"
      },
      "source": [
        "This seems to work quite well, so we can continue with our EDA on the whole dataset.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC5t9I1C4-Mj"
      },
      "source": [
        "#ii) Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jZ6Sl9647Uq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx0z1C6HieNy"
      },
      "source": [
        "##**IV)SENTIMENT ANALYSIS OF FAKE/REAL NEWS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLsoGot9iqQy"
      },
      "source": [
        "##**V)PREDICTING FAKE/REAL NEWS**"
      ]
    }
  ]
}